<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://metal3.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://metal3.io/" rel="alternate" type="text/html" /><updated>2020-02-19T07:35:49+00:00</updated><id>https://metal3.io/feed.xml</id><title type="html">Metal³ - Metal Kubed</title><subtitle>Metal3.io aims to build on baremetal host provisioning technologies to provide a Kubernetes native API for managing bare metal hosts via a provisioning stack that is also running on Kubernetes.</subtitle><entry><title type="html">Metal³: Deploy Kubernetes on Bare Metal - Yolanda Robla - Shift Dev 2019</title><link href="https://metal3.io/blog/2020/01/20/metal3_deploy_kubernetes_on_bare_metal.html" rel="alternate" type="text/html" title="Metal³: Deploy Kubernetes on Bare Metal - Yolanda Robla - Shift Dev 2019" /><published>2020-01-20T07:10:00+00:00</published><updated>2020-01-20T07:10:00+00:00</updated><id>https://metal3.io/blog/2020/01/20/metal3_deploy_kubernetes_on_bare_metal</id><content type="html" xml:base="https://metal3.io/blog/2020/01/20/metal3_deploy_kubernetes_on_bare_metal.html">&lt;h2 id=&quot;conference-talk-metal-deploy-kubernetes-on-bare-metal---yolanda-robla-red-hat&quot;&gt;Conference talk: Metal³: Deploy Kubernetes on Bare Metal - Yolanda Robla, Red Hat&lt;/h2&gt;

&lt;p&gt;Some of the most influential minds in the developer industry were landing in the gorgeous ancient city of Split, Croatia, to talk in the &lt;a href=&quot;https://dev.shiftconf.co&quot;&gt;Shift Dev 2019 - Developer Conference&lt;/a&gt; about the most cutting edge technologies, techniques and biggest trends in the developer space.&lt;/p&gt;

&lt;p&gt;In this video, Yolanda Robla speaks about the deployment of Kubernetes on Bare Metal with the help of Metal³, a new tool that enables the management of bare metal hosts via custom resources managed through the Kubernetes API.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; style=&quot;height: 315px&quot; src=&quot;https://www.youtube.com/embed/iHlaimz48vg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;speakers&quot;&gt;Speakers&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/yolanda-robla-2008158/&quot;&gt;Yolanda Robla&lt;/a&gt; Yolanda Robla is a Principal Software Engineer at Red Hat. In her own words:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In my current position in Red Hat as an NFV Partner Engineer, I investigate new technologies and create proofs of concept for partners to embrace new technologies. Being the current PTL of Akraino, I am involved in designing and implementing systems based on Kubernetes for the Edge use cases, ensuring high scalability and reproducibility using a GitOps approach.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=iHlaimz48vg&amp;amp;t=8s&quot;&gt;Video: Metal³: Deploy Kubernetes on Bare Metal video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">Conference talk: Metal³: Deploy Kubernetes on Bare Metal - Yolanda Robla, Red Hat</summary></entry><entry><title type="html">Introducing Metal³: Kubernetes Native Bare Metal Host Management - Russell Bryant &amp;amp; Doug Hellmann, Red Hat - KubeCon NA, November 2019</title><link href="https://metal3.io/blog/2019/12/04/Introducing_metal3_kubernetes_native_bare_metal_host_management.html" rel="alternate" type="text/html" title="Introducing Metal³: Kubernetes Native Bare Metal Host Management - Russell Bryant &amp; Doug Hellmann, Red Hat - KubeCon NA, November 2019" /><published>2019-12-04T10:09:00+00:00</published><updated>2019-12-04T10:09:00+00:00</updated><id>https://metal3.io/blog/2019/12/04/Introducing_metal3_kubernetes_native_bare_metal_host_management</id><content type="html" xml:base="https://metal3.io/blog/2019/12/04/Introducing_metal3_kubernetes_native_bare_metal_host_management.html">&lt;h2 id=&quot;conference-talk-introducing-metal-kubernetes-native-bare-metal-host-management---russell-bryant--doug-hellmann-red-hat&quot;&gt;Conference talk: Introducing Metal³: Kubernetes Native Bare Metal Host Management - Russell Bryant &amp;amp; Doug Hellmann, Red Hat&lt;/h2&gt;

&lt;p&gt;Metal³ (“metal kubed”) is a new open source bare metal host provisioning tool created to enable Kubernetes-native infrastructure management. Metal³ enables the management of bare metal hosts via custom resources managed through the Kubernetes API as well as the monitoring of bare metal host metrics to Prometheus. This presentation will explain the motivations behind creating the project and what has been accomplished so far. This will be followed by an architectural overview and description of the Custom Resource Definitions (CRDs) for describing bare metal hosts, leading to a demonstration of using Metal³ in a Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;In this video, Russell Bryant and Doug Hellmann speak about the whats and hows of Metal³, a new tool that enables the management of bare metal hosts via custom resources managed through the Kubernetes API.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; style=&quot;height: 315px&quot; src=&quot;https://www.youtube.com/embed/KIIkVD7gujY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;speakers&quot;&gt;Speakers&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.russellbryant.net/&quot;&gt;Russell Bryant&lt;/a&gt; Russell Bryant is a Distinguished Engineer at Red Hat, where he works on infrastructure management to support Kubernetes clusters. Prior to working on the Metal³ project, Russell has worked on other open infrastructure projects. Russell worked in Software Defined Networking with Open vSwitch (OVS) and Open Virtual Network (OVN) and worked on various parts of OpenStack. Russell also worked in open source telephony via the Asterisk project.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://twitter.com/doughellmann&quot;&gt;Doug Hellmann&lt;/a&gt; Doug Hellmann is a Senior Principal Software Engineer at Red Hat. He has been a professional developer since the mid 1990s and has worked on a variety of projects in fields such as mapping, medical news publishing, banking, data center automation, and hardware provisioning. He has been contributing to open source projects for most of his career and for the past 7 years he has been focusing on open source cloud computing technologies, including OpenStack and Kubernetes.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://static.sched.com/hosted_files/kccncna19/b3/Introducing%20Metal3%20KubeCon%20NA%202019.pdf&quot;&gt;Presentation: Introducing Metal³ KubeCon NA 2019 PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=KIIkVD7gujY&amp;amp;feature=emb_logo&quot;&gt;Video: Introducing Metal³: Kubernetes Native Bare Metal Host Management video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;demos&quot;&gt;Demos&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://asciinema.org/a/uOCLoCiOlMLMBLuHOcV2ZvZxb&quot;&gt;First demo (Inspection)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://asciinema.org/a/283704&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/283704.svg&quot; alt=&quot;asciicast&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://asciinema.org/a/Z4a4MhXd7DStprfyiiworS2Id&quot;&gt;Second demo (Provisioning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://asciinema.org/a/283705&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/283705.svg&quot; alt=&quot;asciicast&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://asciinema.org/a/Xs5BPe62kF1PyIkNvMkcC9lyt&quot;&gt;Third demo (Scale up)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://asciinema.org/a/283706&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/283706.svg&quot; alt=&quot;asciicast&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://asciinema.org/a/c5BUvn2iK1J076dI3xLNe4H9C&quot;&gt;Fourth demo (v1alpha2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://asciinema.org/a/283707&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/283707.svg&quot; alt=&quot;asciicast&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">Conference talk: Introducing Metal³: Kubernetes Native Bare Metal Host Management - Russell Bryant &amp;amp; Doug Hellmann, Red Hat</summary></entry><entry><title type="html">Extend Your Data Center to the Hybrid Edge - Red Hat Summit, May 2019</title><link href="https://metal3.io/blog/2019/11/13/Extend_Your_Data_Center_to_the_Hybrid_Edge-Red_Hat_Summit.html" rel="alternate" type="text/html" title="Extend Your Data Center to the Hybrid Edge - Red Hat Summit, May 2019" /><published>2019-11-13T08:37:00+00:00</published><updated>2019-11-13T08:37:00+00:00</updated><id>https://metal3.io/blog/2019/11/13/Extend_Your_Data_Center_to_the_Hybrid_Edge-Red_Hat_Summit</id><content type="html" xml:base="https://metal3.io/blog/2019/11/13/Extend_Your_Data_Center_to_the_Hybrid_Edge-Red_Hat_Summit.html">&lt;h2 id=&quot;conference-talk-extend-your-data-center-to-the-hybrid-edge---red-hat-summit-may-2019-paul-cormier-burr-stutter-and-garima-sharma&quot;&gt;Conference talk: Extend Your Data Center to the Hybrid Edge - Red Hat Summit, May 2019, Paul Cormier, Burr Stutter and Garima Sharma&lt;/h2&gt;

&lt;p&gt;A critical part of being successful in the hybrid cloud is being successful in your data center with your own infrastructure.&lt;/p&gt;

&lt;p&gt;In this video, Paul Cormier, Burr Sutter and Garima Sharma show how you can bring the Open Hybrid cloud to the edge. Cluster management from multiple cloud providers to on premise. In the demo you’ll see a multi-cluster inventory for the open hybrid cloud at cloud.redhat.com, OpenShift Container Storage providing storage for Virtual Machines and containers (Cloud, Virtualization and bare metal), and everything Kubernetes native.&lt;/p&gt;

&lt;h2 id=&quot;speakers&quot;&gt;Speakers&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.redhat.com/en/about/company/management/paul-cormier&quot;&gt;Paul Cormier&lt;/a&gt; Executive vice president and president, Products and Technologies. Leads Red Hat’s technology and products organizations, including engineering, product management, and product marketing for Red Hat’s technologies. He joined Red Hat in May 2001 as executive vice president, Engineering.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://burrsutter.com/&quot;&gt;Burr Sutter&lt;/a&gt; A lifelong developer advocate, community organizer, and technology evangelist, Burr Sutter is a featured speaker at technology events around the globe —from Bangalore to Brussels and Berlin to Beijing (and most parts in between)— he is currently Director of Developer Experience at Red Hat. A Java Champion since 2005 and former president of the Atlanta Java User Group, Burr founded the DevNexus conference —now the second largest Java event in the U.S.— with the aim of making access to the world’s leading developers affordable to the developer community.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/garimasharma/&quot;&gt;Garima Sharma&lt;/a&gt; Senior Engineering leader at world’s largest Open Source company. As a seasoned Tech professional, she runs a global team of Solutions Engineers focused on a large portfolio of Cloud Computing products and technology. She has helped shape science and technology for mission critical software, reliability in operations and re-design of architecture all geared towards advancements in medicine, security, cloud technologies and bottom line savings for the client businesses.  Whether leading the architecture, development and delivery of customer centric cutting edge systems, or spearheading diversity and inclusion initiatives via keynotes, blogs and conference presentations, Garima champions the idea of STEM.  Garima ardently believes in Maya Angelou’s message that diversity makes for a rich tapestry, and we must understand that all the threads of the tapestry are equal in value no matter what their color.&lt;/p&gt;

&lt;h2 id=&quot;video&quot;&gt;Video&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.pscp.tv/RedHatOfficial/1vAGRWYPjngJl?t=1h27m51s&quot;&gt;Extend Your Data Center to the Hybrid Edge - Red Hat Summit, May 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">Conference talk: Extend Your Data Center to the Hybrid Edge - Red Hat Summit, May 2019, Paul Cormier, Burr Stutter and Garima Sharma</summary></entry><entry><title type="html">Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat</title><link href="https://metal3.io/blog/2019/11/07/Kubernetes-native_Infrastructure-Managed_Baremetal_with_Kubernetes_Operators_and_OpenStack_Ironic.html" rel="alternate" type="text/html" title="Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat" /><published>2019-11-07T11:02:00+00:00</published><updated>2019-11-07T11:02:00+00:00</updated><id>https://metal3.io/blog/2019/11/07/Kubernetes-native_Infrastructure-Managed_Baremetal_with_Kubernetes_Operators_and_OpenStack_Ironic</id><content type="html" xml:base="https://metal3.io/blog/2019/11/07/Kubernetes-native_Infrastructure-Managed_Baremetal_with_Kubernetes_Operators_and_OpenStack_Ironic.html">&lt;h2 id=&quot;conference-talk-open-infrastructure-days-uk-2019-kubernetes-native-infrastructure-managed-baremetal-with-kubernetes-operators-and-openstack-ironic---steve-hardy-red-hat&quot;&gt;Conference talk: Open Infrastructure Days UK 2019; Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat&lt;/h2&gt;

&lt;p&gt;In this session you can hear about a new effort to enable baremetal Kubernetes deployments using native interfaces, and in particular the Kubernetes Operator framework, combined with OpenStack Ironic.&lt;/p&gt;

&lt;p&gt;This approach aims to seamlessly integrate your infrastructure with your workloads, including baremetal servers, storage and container/VM workloads.  All this can be achieved using kubernetes native applications, combined with existing, proven deployment and storage tooling.&lt;/p&gt;

&lt;p&gt;In this talk we cover the options around Kubernetes deployments today, the specific approach taken by the new Kubernetes-native “Metalkube” project, and the status/roadmap of this new community effort.&lt;/p&gt;

&lt;h2 id=&quot;speakers&quot;&gt;Speakers&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://hardysteven.blogspot.com&quot;&gt;Steve Hardy&lt;/a&gt; is Senior Principal Software Engineer at Red Hat, currently involved in kubernetes/OpenShift deployment and architecture. He is also an active member of the OpenStack community, and has been a project team lead of both the Heat (orchestration) and TripleO (deployment) projects.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://openinfradays.sched.com/event/KMyE&quot;&gt;Open Infrastructure Days UK 2019, Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">Conference talk: Open Infrastructure Days UK 2019; Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat</summary></entry><entry><title type="html">OpenStack Ironic and Bare Metal Infrastructure: All Abstractions Start Somewhere - Chris Hoge, OpenStack Foundation; Julia Kreger, Red Hat</title><link href="https://metal3.io/blog/2019/10/31/OpenStack-Ironic-and-Bare-Metal-Infrastructure_All-Abstractions-Start-Somewhere.html" rel="alternate" type="text/html" title="OpenStack Ironic and Bare Metal Infrastructure: All Abstractions Start Somewhere - Chris Hoge, OpenStack Foundation; Julia Kreger, Red Hat" /><published>2019-10-31T06:25:00+00:00</published><updated>2019-10-31T06:25:00+00:00</updated><id>https://metal3.io/blog/2019/10/31/OpenStack-Ironic-and-Bare-Metal-Infrastructure_All-Abstractions-Start-Somewhere</id><content type="html" xml:base="https://metal3.io/blog/2019/10/31/OpenStack-Ironic-and-Bare-Metal-Infrastructure_All-Abstractions-Start-Somewhere.html">&lt;h2 id=&quot;conference-talk-openstack-ironic-and-bare-metal-infrastructure-all-abstractions-start-somewhere&quot;&gt;Conference talk: OpenStack Ironic and Bare Metal Infrastructure: All Abstractions Start Somewhere&lt;/h2&gt;

&lt;p&gt;The history of cloud computing has rapidly layered abstractions on abstractions to deliver applications faster, more reliably, and easier. Serverless functions on top of containers on top of virtualization. However, at the bottom of every stack is physical hardware that has an entire lifecycle that needs to be managed.&lt;/p&gt;

&lt;p&gt;In this video, Chris and Julia show how OpenStack Ironic  is a solution to the problem of managing bare-metal infrastructure.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; style=&quot;height: 315px&quot; src=&quot;https://www.youtube.com/embed/Nzq2S53nk9U&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;speakers&quot;&gt;Speakers&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/hogepodge&quot;&gt;Chris Hoge&lt;/a&gt; is a Senior Strategic Program Manager for the OpenSatck foundation. He’s been an active contributor to the Interop Working Group (formerly DefCore), and helps run the trademark program for the OpenStack Foundation. He also works on collaborations between the OpenStack and Kubernetes communities. Previously he worked as an OpenStack community manager and developer at Puppet Labs, and operated a research cloud for the College of Arts and Sciences at The University of Oregon. When not cloud computing, he enjoys long-distance running, dancing, and throwing a ball for his Border Collie.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/ashinclouds&quot;&gt;Julia Kreger&lt;/a&gt; is Principal Software Engineer at Red Hat. She started her career in networking and eventually shifted to systems engineering. The DevOps movement lead her into software development and the operationalization of software due to the need to automate large scale systems deployments. She is experienced in conveying an operational perspective while bridging that with requirements and doesn’t mind getting deep down into code to solve a problem.
She is an active core contributor and leader in OpenStack Ironic project, which is a project she feels passionate about due to many misspent hours in data centers deploying hardware. Prior to OpenStack, Julia contributed to the Shared Learning Infrastructure and worked with large scale litigation database systems.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openstack.org/summit/denver-2019/summit-schedule/events/23779/openstack-ironic-and-bare-metal-infrastructure-all-abstractions-start-somewhere&quot;&gt;Open Infraestructure Summit, Denver, CO, April 29 - May 1, 2019&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openstack.org/videos/summits/denver-2019/openstack-ironic-and-bare-metal-infrastructure-all-abstractions-start-somewhere&quot;&gt;OpenStack Ironic and Bare Metal Infrastructure: All Abstractions Start Somewhere&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">Conference talk: OpenStack Ironic and Bare Metal Infrastructure: All Abstractions Start Somewhere</summary></entry><entry><title type="html">Baremetal Operator</title><link href="https://metal3.io/blog/2019/09/11/Baremetal-operator.html" rel="alternate" type="text/html" title="Baremetal Operator" /><published>2019-09-11T11:00:00+00:00</published><updated>2019-09-11T11:00:00+00:00</updated><id>https://metal3.io/blog/2019/09/11/Baremetal-operator</id><content type="html" xml:base="https://metal3.io/blog/2019/09/11/Baremetal-operator.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator/&quot;&gt;baremetal operator&lt;/a&gt;, documented at &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator/blob/master/docs/api.md&quot;&gt;https://github.com/metal3-io/baremetal-operator/blob/master/docs/api.md&lt;/a&gt;, it’s the Operator in charge of definitions of physical hosts, containing information about how to reach the Out of Band management controller, URL with the desired image to provision, plus other properties related with hosts being used for provisioning instances.&lt;/p&gt;

&lt;p&gt;Quoting from the project:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The Bare Metal Operator implements a Kubernetes API for managing bare metal hosts. It maintains an inventory of available hosts as instances of the BareMetalHost Custom Resource Definition. The Bare Metal Operator knows how to:
   Inspect the host’s hardware details and report them on the corresponding BareMetalHost. This includes information about CPUs, RAM, disks, NICs, and more.
   Provision hosts with a desired image
   Clean a host’s disk contents before or after provisioning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;a-bit-more-in-deep-approach&quot;&gt;A bit more in deep approach&lt;/h2&gt;

&lt;p&gt;The Baremetal Operator (BMO) keeps a mapping of each host and its management interfaces (vendor based like &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;iLO&lt;/code&gt;, &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;iDrac&lt;/code&gt;, &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;iRMC&lt;/code&gt;, etc) and controlled via &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;IPMI&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;All of this is defined in a &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;CRD&lt;/code&gt;, for example:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01-credentials&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;YWRtaW4=&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;YWRtaW4=&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;BareMetalHost&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bmc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ipmi://172.22.0.2:6230&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;credentialsName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01-credentials&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bootMACAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;00:c2:fc:3b:e1:01&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;hardwareProfile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;libvirt&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;online&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With above values (described in &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator/blob/master/docs/api.md&quot;&gt;API&lt;/a&gt;), we’re telling the operator:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MAC: Defines the mac address of the NIC connected to the network that will be used for provision the host&lt;/li&gt;
  &lt;li&gt;bmc: defines the management controller address and the secret used&lt;/li&gt;
  &lt;li&gt;credentialsName: Defines the name of the secret containing username/password for accessing the IPMI service&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once the server is ‘defined’ via the CRD, the underlying service (provided by &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;ironic&lt;/code&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; as of this writing) is inspected:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;gp&quot;&gt;[root@metal3-kubernetes ~]#&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;kubectl get baremetalhost &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; metal3
&lt;span class=&quot;go&quot;&gt;NAME            STATUS   PROVISIONING STATUS   CONSUMER   BMC                      HARDWARE PROFILE   ONLINE   ERROR
metal3-node01   OK       inspecting                       ipmi://172.22.0.1:6230                      false
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the inspection has finished, the status will change to &lt;em&gt;ready&lt;/em&gt; and made available for provisioning.&lt;/p&gt;

&lt;p&gt;When we define a machine, we refer the images that will be used for the actual provisioning in the CRD (&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;image&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DATA&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01-user-data&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cluster.k8s.io/v1alpha1&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Machine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;generateName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;baremetal-machine-&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;providerSpec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;baremetal.cluster.k8s.io/v1alpha1&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BareMetalMachineProviderSpec&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://172.22.0.2/images/CentOS-7-x86_64-GenericCloud-1901.qcow2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;checksum&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://172.22.0.2/images/CentOS-7-x86_64-GenericCloud-1901.qcow2.md5sum&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3-node01-user-data&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;gp&quot;&gt;[root@metal3-kubernetes ~]#&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; metal3-node01-machine.yml
&lt;span class=&quot;go&quot;&gt;secret/metal3-node01-user-data created
machine.cluster.k8s.io/metal3-node01 created
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s examine the annotation created when provisioning (&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;metal3.io/BareMetalHost&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;gp&quot;&gt;[root@metal3-kubernetes ~]#&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;kubectl get machine &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; metal3 metal3-node01 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml
&lt;span class=&quot;go&quot;&gt;apiVersion: cluster.k8s.io/v1alpha1
kind: Machine
metadata:
  annotations:
    metal3.io/BareMetalHost: metal3/metal3-node01
  creationTimestamp: &quot;2019-07-08T15:30:44Z&quot;
  finalizers:
  - machine.cluster.k8s.io
  generateName: baremetal-machine-
  generation: 2
  name: metal3-node01
  namespace: metal3
  resourceVersion: &quot;6222&quot;
  selfLink: /apis/cluster.k8s.io/v1alpha1/namespaces/metal3/machines/metal3-node01
  uid: 1bfd384a-5467-43b7-98aa-e80e1ace5ce7
spec:
  metadata:
    creationTimestamp: null
  providerSpec:
    value:
      apiVersion: baremetal.cluster.k8s.io/v1alpha1
      image:
        checksum: http://172.22.0.1/images/CentOS-7-x86_64-GenericCloud-1901.qcow2.md5sum
        url: http://172.22.0.1/images/CentOS-7-x86_64-GenericCloud-1901.qcow2
      kind: BareMetalMachineProviderSpec
      userData:
        name: metal3-node01-user-data
        namespace: metal3
  versions:
    kubelet: &quot;&quot;
status:
  addresses:
  - address: 192.168.122.79
    type: InternalIP
  - address: 172.22.0.39
    type: InternalIP
  - address: localhost.localdomain
    type: Hostname
  lastUpdated: &quot;2019-07-08T15:30:44Z&quot;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p&gt;In the output above, the host assigned was the one we’ve defined earlier as well as the other parameters like IP’s, etc generated.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, if we check baremetal hosts, we can see how it’s getting provisioned:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;gp&quot;&gt;[root@metal3-kubernetes ~]#&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;kubectl get baremetalhost &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; metal3
&lt;span class=&quot;go&quot;&gt;NAME            STATUS   PROVISIONING STATUS   CONSUMER   BMC                      HARDWARE PROFILE   ONLINE   ERROR
metal3-node01   OK       provisioned                       ipmi://172.22.0.1:6230                     true
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And also, check it via the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;ironic&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;gp&quot;&gt;[root@metal3-kubernetes ~]#&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OS_TOKEN&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;fake-token &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OS_URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;http://localhost:6385 &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; openstack baremetal node list
&lt;span class=&quot;go&quot;&gt;+--------------------------------------+---------------+--------------------------------------+-------------+--------------------+-------------+
| UUID                                 | Name          | Instance UUID                        | Power State | Provisioning State | Maintenance |
+--------------------------------------+---------------+--------------------------------------+-------------+--------------------+-------------+
| 7551cfb4-d758-4ad8-9188-859ee53cf298 | metal3-node01 | 7551cfb4-d758-4ad8-9188-859ee53cf298 | power on    | active             | False       |
+--------------------------------------+---------------+--------------------------------------+-------------+--------------------+-------------+
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;wrap-up&quot;&gt;Wrap-up&lt;/h2&gt;

&lt;p&gt;We’ve seen how via a CRD we’ve defined credentials for a baremetal host to make it available to get provisioned and how we’ve also defined a machine that was provisioned on top of that baremetal host.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Ironic was chosen as the initial provider for baremetal provisioning, check &lt;a href=&quot;https://github.com/metal3-io/metal3-docs/blob/master/design/use-ironic.md&quot;&gt;Ironic documentation&lt;/a&gt; for more details about Ironic usage in Metal³ &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Pablo Iranzo Gómez</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Metal3</title><link href="https://metal3.io/blog/2019/06/25/Metal3.html" rel="alternate" type="text/html" title="Metal3" /><published>2019-06-25T15:19:14+00:00</published><updated>2019-06-25T15:19:14+00:00</updated><id>https://metal3.io/blog/2019/06/25/Metal3</id><content type="html" xml:base="https://metal3.io/blog/2019/06/25/Metal3.html">&lt;p&gt;Originally posted at &lt;a href=&quot;https://www.underkube.com/posts/metal3/&quot;&gt;https://www.underkube.com/posts/metal3/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this blog post, I’m going to try to explain in my own words a high level
overview of what &lt;a href=&quot;https://metal3.io&quot;&gt;Metal3&lt;/a&gt; is, the motivation behind it and some concepts related
to a ‘baremetal operator’.&lt;/p&gt;

&lt;p&gt;Let’s have some definitions!&lt;/p&gt;

&lt;h2 id=&quot;custom-resource-definition&quot;&gt;Custom Resource Definition&lt;/h2&gt;
&lt;p&gt;The k8s API provides some out-of-the-box objects such as pods, services, etc.
There are a few methods of &lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/&quot;&gt;extending the k8s API&lt;/a&gt; (such as API extensions)
but since a few releases back, the k8s API can be extended easily with &lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&quot;&gt;custom resources definitions&lt;/a&gt; (CRDs).
Basically this means you can virtually create any type of object &lt;strong&gt;definition&lt;/strong&gt; in k8s
(actually only user with cluster-admin capabilities) with a yaml such as:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apiextensions.k8s.io/v1beta1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CustomResourceDefinition&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# name must match the spec fields below, and be in the form: &amp;lt;plural&amp;gt;.&amp;lt;group&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;crontabs.stable.example.com&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# group name to use for REST API: /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;stable.example.com&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# list of versions supported by this CustomResourceDefinition&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;versions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# Each version can be enabled/disabled by Served flag.&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;served&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# One and only one version must be marked as the storage version.&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# either Namespaced or Cluster&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Namespaced&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# plural name to be used in the URL: /apis/&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;plural&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;plural&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;crontabs&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# singular name to be used as an alias on the CLI and for display&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;singular&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;crontab&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# kind is normally the CamelCased singular type. Your resource manifests use this.&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CronTab&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# shortNames allow shorter string to match your resource on the CLI&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;shortNames&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ct&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;preserveUnknownFields&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;validation&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;openAPIV3Schema&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;object&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;object&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;cronSpec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;string&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;string&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;integer&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And after &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;kubectl apply -f&lt;/code&gt; you can &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;kubectl get crontabs&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There are tons of information with regards to CRDs, like the &lt;a href=&quot;https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&quot;&gt;k8s official documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The CRD by himself is not useful ‘per se’ as nobody will take care of it (that’s why I said &lt;strong&gt;definition&lt;/strong&gt;). It
requires a &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;controller&lt;/code&gt; to watch for those new objects and react to different
events affecting the object.&lt;/p&gt;

&lt;h2 id=&quot;controller&quot;&gt;Controller&lt;/h2&gt;

&lt;p&gt;A controller is basically a loop that watches the current status of an object
and if it is different from the desired status, it fix it (reconciliation).
This is why k8s is ‘declarative’, you specify the object desired status instead
‘how to do it’ (imperative).&lt;/p&gt;

&lt;p&gt;Again, there are tons of documentation (and &lt;a href=&quot;https://github.com/kubernetes/sample-controller&quot;&gt;examples&lt;/a&gt;) around the &lt;a href=&quot;https://engineering.bitnami.com/articles/a-deep-dive-into-kubernetes-controllers.html&quot;&gt;controller&lt;/a&gt; pattern which is
basically the k8s roots, so I’ll let your google-foo take care of it :)&lt;/p&gt;

&lt;h2 id=&quot;operator&quot;&gt;Operator&lt;/h2&gt;

&lt;p&gt;An Operator (in k8s slang) is an application running in your k8s
cluster that deploys, manages and maintain (so, operates) a k8s application.&lt;/p&gt;

&lt;p&gt;This k8s application (the one that the operator manages), can be as simple as a ‘hello world’ application
containerized and deployed in your k8s cluster or it can be a much more complex
thing, such a database cluster.&lt;/p&gt;

&lt;p&gt;The ‘operator’ is like an ‘expert sysadmin’ containerized that takes care of
your application.&lt;/p&gt;

&lt;p&gt;Bear in mind that the ‘expert’ tag (meaning the automation behind the operator)
depends on the operator implementation… so there can be basic operators that
only deploy your application or complex operators that handle day 2 operations
such as upgrades, fail overs, backup/restore, etc.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://coreos.com/operators/&quot;&gt;CoreOS operator definition&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h2 id=&quot;cloud-controller-manager&quot;&gt;Cloud Controller Manager&lt;/h2&gt;

&lt;p&gt;k8s code is smart enough to be able to leverage
the underlying infrastructure where the cluster is running, such as being able
of creating ‘LoadBalancer’ services, understanding the cluster topology based on the cloud provider AZs where the nodes are running (for scheduling reasons), etc.&lt;/p&gt;

&lt;p&gt;This task of ‘talking to the cloud provider’ is performed by the Cloud Controller Manager (CCM) and for more
information you can take a look at the official k8s documentation with
regards the &lt;a href=&quot;https://kubernetes.io/docs/concepts/architecture/cloud-controller/&quot;&gt;architecture&lt;/a&gt; and the &lt;a href=&quot;https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#cloud-controller-manager&quot;&gt;administration&lt;/a&gt; (also, if you are brave enough, you can create your own &lt;a href=&quot;https://kubernetes.io/docs/tasks/administer-cluster/developing-cloud-controller-manager/&quot;&gt;cloud controller manager&lt;/a&gt; )&lt;/p&gt;

&lt;h2 id=&quot;cluster-api&quot;&gt;Cluster API&lt;/h2&gt;

&lt;p&gt;The Cluster API implementation is a WIP ‘framework’ that allows a k8s cluster to manage itself, including the ability of creating new clusters, adding more nodes, etc. in a ‘k8s way’ (declarative, controllers, CRDs, etc.), so there are objects such as &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Cluster&lt;/code&gt; that can be expressed as k8s objects:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cluster.k8s.io/v1alpha1&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Cluster&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mycluster&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;clusterNetwork&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;cidrBlocks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;10.96.0.0/12&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pods&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;cidrBlocks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;192.168.0.0/16&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;serviceDomain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cluster.local&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;providerSpec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but also:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api/blob/60933cb23498d0621f57454c208fc3a8d6e18bf2/api/v1alpha2/machine_types.go&quot;&gt;Machine type objects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;[MachineSet type objects]&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api/blob/60933cb23498d0621f57454c208fc3a8d6e18bf2/api/v1alpha2/machineset_types.go&quot;&gt;(https://github.com/kubernetes-sigs/cluster-api/blob/master/pkg/apis/cluster/v1alpha1/machineset_types.go&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api/blob/60933cb23498d0621f57454c208fc3a8d6e18bf2/api/v1alpha2/machinedeployment_types.go&quot;&gt;MachineDeployment type objects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api/tree/60933cb23498d0621f57454c208fc3a8d6e18bf2/api/v1alpha2&quot;&gt;etc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are some
provider implementations in the wild such as the AWS, Azure, GCP, OpenStack,
vSphere, etc. ones and the Cluster API project is driven by the &lt;a href=&quot;https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle&quot;&gt;SIG Cluster Lifecycle&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please review the official &lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api&quot;&gt;Cluster API&lt;/a&gt; repository for more information.&lt;/p&gt;

&lt;h3 id=&quot;actuator&quot;&gt;Actuator&lt;/h3&gt;

&lt;p&gt;The &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;actuator&lt;/code&gt; is a Cluster API interface that reacts to changes to &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt;
objects reconciliating the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; status.&lt;/p&gt;

&lt;p&gt;The actuator code is tightly coupled with the provider (that’s why it is an
interface) such as the &lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api-provider-aws/blob/25376aa086f183a13f1d50cbb23dd250c03d3137/pkg/cloud/actuators/cluster/actuator.go&quot;&gt;AWS one&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;machineset-vs-machine&quot;&gt;MachineSet vs Machine&lt;/h2&gt;

&lt;p&gt;To simplify, let’s say that &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;MachineSets&lt;/code&gt; are to &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machines&lt;/code&gt; what &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;ReplicaSets&lt;/code&gt; are
to &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Pods&lt;/code&gt;. So you can scale the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machines&lt;/code&gt; in your cluster just by changing
the number of replicas of a &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;MachineSet&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;cluster-api-vs-cloud-providers&quot;&gt;Cluster API vs Cloud Providers&lt;/h2&gt;

&lt;p&gt;As we have seen, the Cluster API leverages the provider related to the k8s
infrastructure itself (clusters and nodes) and the CCM and the cloud provider
integration for k8s is to leverage the cloud provider to provide support infrastructure.&lt;/p&gt;

&lt;p&gt;Let’s say Cluster API is for the k8s administrators and the
CCM is for the k8s users :)&lt;/p&gt;

&lt;h2 id=&quot;machine-api&quot;&gt;Machine API&lt;/h2&gt;

&lt;p&gt;The OpenShift 4 Machine API is a combination of some of the upstream Cluster API
with custom OpenShift resources and it is designed to work in conjunction with
the &lt;a href=&quot;https://github.com/openshift/cluster-version-operator&quot;&gt;Cluster Version Operator&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;openshifts-machine-api-operator&quot;&gt;OpenShift’s Machine API Operator&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/openshift/machine-api-operator&quot;&gt;machine-api-operator&lt;/a&gt; is
an operator that manages the Machine API objects in an OpenShift 4 cluster.&lt;/p&gt;

&lt;p&gt;The operator is capable of creating machines in AWS and libvirt (more providers
coming soon) via the &lt;a href=&quot;https://github.com/openshift/cluster-api/tree/master/pkg/controller/machine&quot;&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine Controller&lt;/code&gt;&lt;/a&gt; and it is included out of the
box with OCP 4 (and &lt;a href=&quot;https://github.com/openshift/machine-api-operator#dev&quot;&gt;can be deployed in a k8s vanilla as well&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;baremetal&quot;&gt;Baremetal&lt;/h2&gt;

&lt;p&gt;A baremetal server (or bare-metal) is just a computer server.&lt;/p&gt;

&lt;p&gt;The last years terms such as virtualization, containers, serverless, etc. have been
popular but at the end of the day, all the code running on top of a SaaS, PaaS
or IaaS is actually running in a real physical server stored in a datacenter
wired to routers, switches and power. That server is a ‘baremetal’ server.&lt;/p&gt;

&lt;p&gt;If you are used to cloud providers and instances, you probably don’t know the
pains of baremetal management… including things such as connecting to the
virtual console (usually it requires an old java version) to debug issues,
configuring pxe for provisioning baremetal hosts (or attach ISOs via the virtual console… or insert a CD/DVD physically into the CD carry if you are
‘lucky’ enough…), configuring VLANs for traffic isolation, etc.&lt;/p&gt;

&lt;p&gt;That kind of operations is not ‘cloud’ ready and there are tools that provide
baremetal management, such as &lt;a href=&quot;https://maas.io/&quot;&gt;maas&lt;/a&gt; or &lt;a href=&quot;https://wiki.openstack.org/wiki/Ironic&quot;&gt;ironic&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ironic&quot;&gt;Ironic&lt;/h2&gt;

&lt;p&gt;OpenStack bare metal provisioning (or ironic) is an open source project (or even better, a number of open source projects) to manage baremetal hosts. Ironic avoids the administrator to deal with pxe configuration, manual deployments, etc. and provides a defined API and a series of plugins to interact with different baremetal models and vendors.&lt;/p&gt;

&lt;p&gt;Ironic is used in OpenStack to provide &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;baremetal&lt;/code&gt; objects but there are some
projects (such as &lt;a href=&quot;https://docs.openstack.org/bifrost/latest/&quot;&gt;bifrost&lt;/a&gt;) to use
Ironic ‘standalone’ (so, no OpenStack required)&lt;/p&gt;

&lt;h2 id=&quot;metal3&quot;&gt;Metal3&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://metal3.io&quot;&gt;Metal3&lt;/a&gt; is a project aimed at providing a baremetal operator that
implements the Cluster API framework required to be able to manage baremetal
in a k8s way (easy peasy!). It uses &lt;a href=&quot;https://github.com/metal3-io/metal3-docs/blob/master/design/use-ironic.md&quot;&gt;ironic under the hood&lt;/a&gt; to avoid reinventing the
wheel, but consider it as an implementation detail that may change.&lt;/p&gt;

&lt;p&gt;The Metal3 baremetal operator watches for &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; (CRD) objects defined as:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metal3.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;BareMetalHost&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-worker-0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;online&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bootMACAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;00:11:22:33:44:55&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bmc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ipmi://my-worker-0.ipmi.example.com&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;credentialsName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-worker-0-bmc-secret&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are a few more fields in the &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator/blob/master/pkg/apis/metal3/v1alpha1/baremetalhost_types.go&quot;&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; object&lt;/a&gt; such as the image, hardware profile, etc.&lt;/p&gt;

&lt;p&gt;The Metal3 project is actually divided into two different components:&lt;/p&gt;

&lt;h3 id=&quot;baremetal-operator&quot;&gt;baremetal-operator&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator&quot;&gt;Metal3 baremetal-operator&lt;/a&gt; is the component that manages baremetal hosts. It exposes a new &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; custom resource in the k8s API that lets you manage hosts in a declarative way.&lt;/p&gt;

&lt;h3 id=&quot;cluster-api-provider-baremetal&quot;&gt;cluster-api-provider-baremetal&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/metal3-io/cluster-api-provider-baremetal&quot;&gt;Metal3 cluster-api-provider-baremetal&lt;/a&gt; includes the integration with the Cluster API project. This provider currently includes a Machine actuator that acts as a client of the BareMetalHost custom resources.&lt;/p&gt;

&lt;h2 id=&quot;baremetalhost-vs-machine-vs-node&quot;&gt;BareMetalHost vs Machine vs Node&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; is a Metal3 object&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; is a Cluster API object&lt;/li&gt;
  &lt;li&gt;Node is where the pods run :)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Those three concepts are linked in a 1:1:1 relationship meaning:&lt;/p&gt;

&lt;p&gt;A &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; created with Metal3 maps to a &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; object and once the
installation procedure finishes, a new kubernetes node will be added to the
cluster.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME                                         STATUS   ROLES    AGE   VERSION
my-node-0.example.com                        Ready    master   25h   v1.14.0

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get machines &lt;span class=&quot;nt&quot;&gt;--all-namespaces&lt;/span&gt;
NAMESPACE               NAME                  INSTANCE   STATE   TYPE   REGION   ZONE   AGE
openshift-machine-api   my-node-0                                                   25h

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts &lt;span class=&quot;nt&quot;&gt;--allnamespaces&lt;/span&gt;
NAMESPACE             NAME      STATUS PROVISIONING STATUS MACHINE BMC HARDWARE PROFILE ONLINE ERROR
openshift-machine-api my-node-0 OK     provisioned  my-node-0.example.com ipmi://1.2.3.4 unknown &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The 1:1 relationship for the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; and the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; is stored in the
&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;machineRef&lt;/code&gt; field in the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;BareMetalHost&lt;/code&gt; object:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl  get baremetalhost/my-node-0 &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; openshift-machine-api &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.spec.machineRef}'&lt;/span&gt;

map[name:my-node-0 namespace:openshift-machine-api]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In a &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; annotation:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get machines my-node-0 &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; openshift-machine-api &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.metadata.annotations}'&lt;/span&gt;
map[metal3.io/BareMetalHost:openshift-machine-api/my-node-0]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The 1:1 relationship for the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; and the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Node&lt;/code&gt; currently requires to
execute the &lt;a href=&quot;https://github.com/openshift-metal3/dev-scripts/blob/master/link-machine-and-node.sh&quot;&gt;link-machine-and-node.sh&lt;/a&gt; script to modify the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt;
object &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;.status&lt;/code&gt; field:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;./link-machine-and-node.sh MACHINE NODE
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, the reference is stored in the &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;.status.nodeRef.name&lt;/code&gt; field in the
&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;Machine&lt;/code&gt; object:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get machine my-node-0 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.status.nodeRef.name}'&lt;/span&gt;

my-node-0.example.com
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;Being able to ‘just scale a node’ in k8s means a lot of underlying concepts and technologies involved behind the scenes :)&lt;/p&gt;

&lt;h2 id=&quot;resourceslinks&quot;&gt;Resources/links&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dzone.com/articles/introducing-the-kubernetes-cluster-api-project-2&quot;&gt;https://dzone.com/articles/introducing-the-kubernetes-cluster-api-project-2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.vmware.com/cloudnative/2019/03/14/what-and-why-of-cluster-api/&quot;&gt;https://blogs.vmware.com/cloudnative/2019/03/14/what-and-why-of-cluster-api/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api&quot;&gt;https://github.com/kubernetes-sigs/cluster-api&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api-provider-aws&quot;&gt;https://github.com/kubernetes-sigs/cluster-api-provider-aws&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://itnext.io/deep-dive-to-cluster-api-a0b4e792d57d&quot;&gt;https://itnext.io/deep-dive-to-cluster-api-a0b4e792d57d&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linux.com/blog/event/kubecon/2018/4/extending-kubernetes-cluster-api&quot;&gt;https://www.linux.com/blog/event/kubecon/2018/4/extending-kubernetes-cluster-api&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Eduardo Minguez</name></author><summary type="html">Originally posted at https://www.underkube.com/posts/metal3/</summary></entry><entry><title type="html">The new stack Metal³ Uses OpenStack’s Ironic for Declarative Bare Metal Kubernetes</title><link href="https://metal3.io/blog/2019/05/13/The_new_stack_Metal3_Uses_OpenStack_Ironic_for_Declarative_Bare_Metal_Kubernetes.html" rel="alternate" type="text/html" title="The new stack Metal³ Uses OpenStack’s Ironic for Declarative Bare Metal Kubernetes" /><published>2019-05-13T08:23:00+00:00</published><updated>2019-05-13T08:23:00+00:00</updated><id>https://metal3.io/blog/2019/05/13/The_new_stack_Metal3_Uses_OpenStack_Ironic_for_Declarative_Bare_Metal_Kubernetes</id><content type="html" xml:base="https://metal3.io/blog/2019/05/13/The_new_stack_Metal3_Uses_OpenStack_Ironic_for_Declarative_Bare_Metal_Kubernetes.html">&lt;h2 id=&quot;the-new-stack-metal-uses-openstacks-ironic-for-declarative-bare-metal-kubernetes&quot;&gt;The new stack Metal³ Uses OpenStack’s Ironic for Declarative Bare Metal Kubernetes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://thenewstack.io/author/mike-melanson/&quot;&gt;Mike Melanson&lt;/a&gt; talks in this article about the Open Infrastructure Summit in Denver, Colorado. Where bare metal was one of the main leads of the event.&lt;/p&gt;

&lt;p&gt;During this event, the OpenStack Foundation unveil a new project called Metal³ (pronounced “metal cubed”) that uses Ironic “as a foundation for declarative management of bare metal infrastructure for Kubernetes”.
He also comments on how &lt;a href=&quot;https://www.linkedin.com/in/penick/&quot;&gt;James Penick&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/hogepodge&quot;&gt;Chris Hoge&lt;/a&gt;, senior strategic program manager at OpenStack Foundation,
and &lt;a href=&quot;https://www.linkedin.com/in/juliaashleykreger&quot;&gt;Julia Kreger&lt;/a&gt;, OpenStack Ironic Project Team Leader, took to the stage to offer a demonstration of &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator&quot;&gt;Metal3&lt;/a&gt;,
the new project that provides “bare metal host provisioning integration for Kubernetes.”&lt;/p&gt;

&lt;p&gt;Some words from Kreger in an interview with The New Stack:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I think the bigger trend that we’re starting to see is a recognition that common tooling and substrate helps everyone succeed faster with more efficiency.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“This is combined with a shift in the way operators are choosing to solve their problems at scale, specifically in regards to isolation, cost, or performance.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For further detail, check out the &lt;a href=&quot;/blog/2019/10/31/OpenStack-Ironic-and-Bare-Metal-Infrastructure_All-Abstractions-Start-Somewhere.html&quot;&gt;video of the keynote&lt;/a&gt;, which includes a demonstration of Metal3 being used to quickly provision three bare metal servers with Kubernetes 
or check the full article included below.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://thenewstack.io/metal3-uses-openstacks-ironic-for-declarative-bare-metal-kubernetes/&quot;&gt;The new stack: Metal³ Uses OpenStack’s Ironic for Declarative Bare Metal Kubernetes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/2019/10/31/OpenStack-Ironic-and-Bare-Metal-Infrastructure_All-Abstractions-Start-Somewhere.html&quot;&gt;Video of the keynote: OpenStack Ironic and Baremetal Infrastructure. All Abstracions start somewhere&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">The new stack Metal³ Uses OpenStack’s Ironic for Declarative Bare Metal Kubernetes</summary></entry><entry><title type="html">Metal³: Baremetal Provisioning for Kubernetes</title><link href="https://metal3.io/blog/2019/04/30/Metal-Kubed-Baremetal-Provisioning-for-Kubernetes.html" rel="alternate" type="text/html" title="Metal³: Baremetal Provisioning for Kubernetes" /><published>2019-04-30T20:01:58+00:00</published><updated>2019-04-30T20:01:58+00:00</updated><id>https://metal3.io/blog/2019/04/30/Metal-Kubed-Baremetal-Provisioning-for-Kubernetes</id><content type="html" xml:base="https://metal3.io/blog/2019/04/30/Metal-Kubed-Baremetal-Provisioning-for-Kubernetes.html">&lt;p&gt;Originally posted at &lt;a href=&quot;https://blog.russellbryant.net/2019/04/30/metal%c2%b3-metal-kubed-bare-metal-provisioning-for-kubernetes/&quot;&gt;https://blog.russellbryant.net/2019/04/30/metal%c2%b3-metal-kubed-bare-metal-provisioning-for-kubernetes/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;project-introduction&quot;&gt;Project Introduction&lt;/h2&gt;

&lt;p&gt;There are a number of great open source tools for bare metal host provisioning, including &lt;a href=&quot;https://docs.openstack.org/ironic/latest/install/refarch/common.html&quot;&gt;Ironic&lt;/a&gt;. Metal³ aims to build on these technologies to provide a Kubernetes native API for managing bare metal hosts via a provisioning stack that is also running on Kubernetes. We believe that Kubernetes Native Infrastructure, or managing your infrastructure just like your applications, is a powerful next step in the evolution of infrastructure management.&lt;/p&gt;

&lt;p&gt;The Metal³ project is also building integration with the Kubernetes &lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api&quot;&gt;cluster-api&lt;/a&gt; project, allowing Metal³ to be used as an infrastructure backend for Machine objects from the Cluster API.&lt;/p&gt;

&lt;h2 id=&quot;metal3-repository-overview&quot;&gt;Metal3 Repository Overview&lt;/h2&gt;

&lt;p&gt;There is a Metal³ overview and some more detailed design documents in the &lt;a href=&quot;https://github.com/metal3-io/metal3-docs&quot;&gt;metal3-docs&lt;/a&gt; repository.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/metal3-io/baremetal-operator&quot;&gt;baremetal-operator&lt;/a&gt; is the component that manages bare metal hosts. It exposes a new BareMetalHost custom resource in the Kubernetes API that lets you manage hosts in a declarative way.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;a href=&quot;https://github.com/metal3-io/cluster-api-provider-baremetal&quot;&gt;cluster-api-provider-baremetal&lt;/a&gt; repository includes integration with the &lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-api&quot;&gt;cluster-api&lt;/a&gt; project. This provider currently includes a Machine actuator that acts as a client of the BareMetalHost custom resources.&lt;/p&gt;

&lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt;

&lt;p&gt;The project has been going for a few months now, and there’s enough now to show some working code.&lt;/p&gt;

&lt;p&gt;For this demonstration, I’ve started with a 3 node Kubernetes cluster installed using &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME       STATUS   ROLES    AGE   VERSION
master-0   Ready    master   24h   v1.13.4+d4ce02c1d
master-1   Ready    master   24h   v1.13.4+d4ce02c1d
master-2   Ready    master   24h   v1.13.4+d4ce02c1d
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Machine objects were created to reflect these 3 masters, as well.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get machines
NAME              INSTANCE   STATE   TYPE   REGION   ZONE   AGE
ostest-master-0                                             24h
ostest-master-1                                             24h
ostest-master-2                                             24h
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For this cluster-api provider, a Machine has a corresponding BareMetalHost object, which corresponds to the piece of hardware we are managing. There is a design document that covers &lt;a href=&quot;https://github.com/metal3-io/metal3-docs/blob/master/design/nodes-machines-and-hosts.md&quot;&gt;the relationship between Nodes, Machines, and BareMetalHosts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since these hosts were provisioned earlier, they are in a special &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;externally provisioned&lt;/code&gt; state, indicating that we enrolled them in management while they were already running in a desired state. If changes are needed going forward, the baremetal-operator will be able to automate them.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE           BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0   ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1   ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2   ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now suppose we’d like to expand this cluster by adding another bare metal host to serve as a worker node. First we need to create a new BareMetalHost object that adds this new host to the inventory of hosts managed by the baremetal-operator. Here’s the YAML for the new BareMetalHost:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openshift-worker-0-bmc-secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;YWRtaW4=&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cGFzc3dvcmQ=&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;metalkube.org/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;BareMetalHost&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openshift-worker-0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;online&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bmc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ipmi://192.168.111.1:6233&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;credentialsName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openshift-worker-0-bmc-secret&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bootMACAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;00:ab:4f:d8:9e:fa&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now to add the BareMetalHost and its IPMI credentials Secret to the cluster:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; worker_crs.yaml
secret/openshift-worker-0-bmc-secret created
baremetalhost.metalkube.org/openshift-worker-0 created
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The list of BareMetalHosts now reflects a new host in the inventory that is ready to be provisioned. It will remain in this &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;ready&lt;/code&gt; state until it is claimed by a new Machine object.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE           BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0   ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1   ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2   ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-worker-0   OK       ready                                      ipmi://192.168.111.1:6233   unknown            &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have a MachineSet already created for workers, but it scaled down to 0.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get machinesets
NAME              DESIRED   CURRENT   READY   AVAILABLE   AGE
ostest-worker-0   0         0                             24h
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can scale this MachineSet to 1 to indicate that we’d like a worker provisioned. The baremetal cluster-api provider will then look for an available BareMetalHost, claim it, and trigger provisioning of that host.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;$ kubectl scale machineset ostest-worker-0 --replicas=1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After the new Machine was created, our cluster-api provider claimed the available host and triggered it to be provisioned.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE                 BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0         ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1         ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2         ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-worker-0   OK       provisioning             ostest-worker-0-jmhtc   ipmi://192.168.111.1:6233   unknown            &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This process takes some time. Under the hood, the baremetal-operator is driving Ironic through a provisioning process. This begins with wiping disks to ensure the host comes up in a clean state. It will eventually write the desired OS image to disk and then reboot into that OS. When complete, a new Kubernetes Node will register with the cluster.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE                 BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0         ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1         ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2         ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-worker-0   OK       provisioned              ostest-worker-0-jmhtc   ipmi://192.168.111.1:6233   unknown            &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME       STATUS   ROLES    AGE   VERSION
master-0   Ready    master   24h   v1.13.4+d4ce02c1d
master-1   Ready    master   24h   v1.13.4+d4ce02c1d
master-2   Ready    master   24h   v1.13.4+d4ce02c1d
worker-0   Ready    worker   68s   v1.13.4+d4ce02c1d
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following screen cast demonstrates this process, as well:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://asciinema.org/a/c1qITPktXyIIHvzDUket3buwQ&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/c1qITPktXyIIHvzDUket3buwQ.svg&quot; alt=&quot;Machine API driven bare metal worker deployment (OpenShift)&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Removing a bare metal host from the cluster is very similar. We just have to scale this MachineSet back down to 0.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-html highlighter-rouge&quot;&gt;$ kubectl scale machineset ostest-worker-0 --replicas=0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Once the Machine has been deleted, the baremetal-operator will deprovision the bare metal host.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE           BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0   ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1   ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2   ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-worker-0   OK       deprovisioning                             ipmi://192.168.111.1:6233   unknown            &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the deprovisioning process is complete, the bare metal host will be back to its &lt;code class=&quot;language-html highlighter-rouge&quot;&gt;ready&lt;/code&gt; state, available in the host inventory to be claimed by a future Machine object.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;syntax&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get baremetalhosts
NAME                 STATUS   PROVISIONING STATUS      MACHINE           BMC                         HARDWARE PROFILE   ONLINE   ERROR
openshift-master-0   OK       externally provisioned   ostest-master-0   ipmi://192.168.111.1:6230                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-1   OK       externally provisioned   ostest-master-1   ipmi://192.168.111.1:6231                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-master-2   OK       externally provisioned   ostest-master-2   ipmi://192.168.111.1:6232                      &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;openshift-worker-0   OK       ready                                      ipmi://192.168.111.1:6233   unknown            &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;getting-involved&quot;&gt;Getting Involved&lt;/h2&gt;

&lt;p&gt;All development is happening on &lt;a href=&quot;https://github.com/metal3-io&quot;&gt;github&lt;/a&gt;. We have a &lt;a href=&quot;https://groups.google.com/forum/#!forum/metal3-dev&quot;&gt;metal3-dev mailing list&lt;/a&gt; and use #cluster-api-baremetal on &lt;a href=&quot;https://slack.k8s.io/&quot;&gt;Kubernetes Slack&lt;/a&gt; to chat. Occasional project updates are posted to &lt;a href=&quot;https://twitter.com/metal3_io&quot;&gt;@metal3_io on Twitter&lt;/a&gt;.&lt;/p&gt;</content><author><name>Russell Bryant</name></author><summary type="html">Originally posted at https://blog.russellbryant.net/2019/04/30/metal%c2%b3-metal-kubed-bare-metal-provisioning-for-kubernetes/</summary></entry><entry><title type="html">Raise some horns, Red Hat’s MetalKube aims to make Kubernetes on bare machines simple</title><link href="https://metal3.io/blog/2019/04/12/Raise_some_horns_Red_Hat_s_MetalKube_aims_to_make_Kubernetes_on_bare_machines_simple.html" rel="alternate" type="text/html" title="Raise some horns, Red Hat's MetalKube aims to make Kubernetes on bare machines simple" /><published>2019-04-12T19:20:00+00:00</published><updated>2019-04-12T19:20:00+00:00</updated><id>https://metal3.io/blog/2019/04/12/Raise_some_horns_Red_Hat_s_MetalKube_aims_to_make_Kubernetes_on_bare_machines_simple</id><content type="html" xml:base="https://metal3.io/blog/2019/04/12/Raise_some_horns_Red_Hat_s_MetalKube_aims_to_make_Kubernetes_on_bare_machines_simple.html">&lt;h2 id=&quot;the-register-raise-some-horns-red-hats-metal-aims-to-make-kubernetes-on-bare-machines-simple&quot;&gt;The Register; Raise some horns: Red Hat’s Metal³ aims to make Kubernetes on bare machines simple&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.theregister.co.uk/Author/Max-Smolaks&quot;&gt;Max Smolaks&lt;/a&gt; talks in this article about the OpenInfra Days in the UK, 2019: where Metal³ was revealed earlier last week by Steve Hardy, Red Hat’s senior principal software engineer. The Open Infrastructure Days in the UK is an event organised by the local Open Infrastructure community and supported by the OpenStack Foundation.
The Open-source software developers at Red Hat are working on a tool that would simplify deployment and management of Kubernetes clusters on bare-metal servers.&lt;/p&gt;

&lt;p&gt;Steve told The reg:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“In some situations, you won’t want to run a full OpenStack infrastructure-as-a-service layer to provide, potentially, for multiple Kubernetes clusters”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hardy is a notable contributor to OpenStack, having previously worked on Heat and TripleO projects. He said one of the reasons for choosing Ironic was its active development – and when new features get added to Ironic, the Metal³ team gets them “for free”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“OpenStack has always been a modular set of projects, and people have always had the opportunity to reuse components for different applications. This is just an example of where we are leveraging one particular component for infrastructure management, just as an alternative to using a full infrastructure API,” Hardy said.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thierry Carrez, veep of engineering at the OpenStack Foundation also told The Reg:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I like the fact that the projects end up being reusable on their own, for the functions they bring to the table – this helps us integrate with adjacent communities”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hardy also commented:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;It’s still early days for Metal³ - the project has just six contributors, and there’s no telling when it might reach release. “It’s a very, very young project but we are keen to get more community participation and feedback,”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For further detail, check out the full article at &lt;a href=&quot;https://www.theregister.co.uk/2019/04/05/red_hat_metalkubel/&quot;&gt;The Register: Raise some horns: Red Hat’s MetalKube aims to make Kubernetes on bare machines simple&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hardysteven.blogspot.com&quot;&gt;Steve Hardy&lt;/a&gt;: Red Hat’s senior principal software engineer.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ttx.re/&quot;&gt;Thierry Carrez&lt;/a&gt;: veep of engineering at the OpenStack Foundation.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.theregister.co.uk/2019/04/05/red_hat_metalkubel/&quot;&gt;The Register: Raise some horns: Red Hat’s MetalKube aims to make Kubernetes on bare machines simple&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Pedro Ibáñez Requena</name></author><summary type="html">The Register; Raise some horns: Red Hat’s Metal³ aims to make Kubernetes on bare machines simple</summary></entry></feed>